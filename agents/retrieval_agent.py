# # agents/retrieval_agent.py
# import os
# import uuid
# from typing import List, Dict, Any
# import fitz  # PyMuPDF
# from sentence_transformers import SentenceTransformer
# import chromadb
# from chromadb.config import Settings
# import numpy as np

# CHROMA_DIR = "chroma_db"

# class RetrievalAgent:
#     def __init__(self, embed_model_name="all-MiniLM-L6-v2", persist_directory=CHROMA_DIR):
#         import torch
#         device = "cuda" if torch.cuda.is_available() else "cpu"
#         self.device = device
#         self.text_embedder = SentenceTransformer(embed_model_name, device=self.device)
#         self.client = chromadb.Client(Settings(chroma_db_impl="duckdb+parquet",
#                                                persist_directory=persist_directory))
#         coll_name = "multimodal_docs"
#         if coll_name in [c.name for c in self.client.list_collections()]:
#             self.col = self.client.get_collection(coll_name)
#         else:
#             self.col = self.client.create_collection(name=coll_name,
#                                                      metadata={"description": "text+image multimodal"})

#     def ingest_pdfs(self, data_dir="data", chunk_chars=900, overlap=200):
#         for root, _, files in os.walk(data_dir):
#             for fn in files:
#                 if fn.lower().endswith(".pdf"):
#                     path = os.path.join(root, fn)
#                     self._process_pdf(path, chunk_chars, overlap)
#         self.client.persist()

#     def _process_pdf(self, path, chunk_chars, overlap):
#         doc = fitz.open(path)
#         # accumulate page text, chunk it
#         for pno in range(len(doc)):
#             page = doc[pno]
#             text = page.get_text().strip()
#             if text:
#                 chunks = self._chunk_text(text, chunk_chars, overlap)
#                 for i, c in enumerate(chunks):
#                     emb = self.text_embedder.encode(c)
#                     uid = str(uuid.uuid4())
#                     meta = {"type": "text", "source": os.path.basename(path), "page": pno+1, "chunk_idx": i}
#                     self.col.add(documents=[c], metadatas=[meta], ids=[uid], embeddings=[emb.tolist()])
#             # extract images
#             images = page.get_images(full=True)
#             for img_index, img in enumerate(images):
#                 xref = img[0]
#                 base_image = doc.extract_image(xref)
#                 ext = base_image["ext"]
#                 image_bytes = base_image["image"]
#                 images_dir = os.path.join(os.path.dirname(path), "images")
#                 os.makedirs(images_dir, exist_ok=True)
#                 img_name = f"{os.path.splitext(os.path.basename(path))[0]}_p{pno+1}_img{img_index}.{ext}"
#                 img_path = os.path.join(images_dir, img_name)
#                 with open(img_path, "wb") as f:
#                     f.write(image_bytes)
#                 # placeholder document; caption will be generated by VisionAgent and updated
#                 placeholder_text = f"[IMAGE] {img_name}"
#                 emb = self.text_embedder.encode(f"image:{img_name}")
#                 uid = str(uuid.uuid4())
#                 meta = {"type":"image", "source": os.path.basename(path), "page": pno+1, "img_path": img_path, "img_name": img_name}
#                 self.col.add(documents=[placeholder_text], metadatas=[meta], ids=[uid], embeddings=[emb.tolist()])

#     def ingest_images_folder(self, images_dir="data/images"):
#         if not os.path.exists(images_dir):
#             return
#         for root, _, files in os.walk(images_dir):
#             for fn in files:
#                 if fn.lower().endswith((".png", ".jpg", ".jpeg")):
#                     p = os.path.join(root, fn)
#                     placeholder = f"[IMAGE] {fn}"
#                     emb = self.text_embedder.encode(f"image:{fn}")
#                     uid = str(uuid.uuid4())
#                     meta = {"type":"image", "source": fn, "img_path": p, "img_name": fn}
#                     self.col.add(documents=[placeholder], metadatas=[meta], ids=[uid], embeddings=[emb.tolist()])

#     def retrieve(self, query: str, top_k: int = 5) -> List[Dict[str,Any]]:
#         q_emb = self.text_embedder.encode(query)
#         res = self.col.query(query_embeddings=[q_emb.tolist()], n_results=top_k)
#         hits = []
#         docs = res.get("documents", [[]])[0]
#         metas = res.get("metadatas", [[]])[0]
#         ids = res.get("ids", [[]])[0]
#         distances = res.get("distances", [[]])[0]
#         for idx, doc in enumerate(docs):
#             hits.append({"id": ids[idx], "document": doc, "metadata": metas[idx], "distance": distances[idx]})
#         return hits

#     def get_all_documents(self):
#         res = self.col.get()
#         rows = []
#         for i in range(len(res["ids"])):
#             rows.append({"id": res["ids"][i], "document": res["documents"][i], "metadata": res["metadatas"][i]})
#         return rows

#     def update_image_caption_embedding(self, item_id: str, caption: str):
#         emb = self.text_embedder.encode(caption)
#         self.col.update(ids=[item_id], embeddings=[emb.tolist()], documents=[caption])

# agents/retrieval_agent.py
import os
import uuid
from typing import List, Dict, Any
import fitz  # PyMuPDF
from sentence_transformers import SentenceTransformer
import chromadb
import numpy as np

CHROMA_DIR = "chroma_db"

class RetrievalAgent:
    def __init__(self, embed_model_name="all-MiniLM-L6-v2", persist_directory=CHROMA_DIR):
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"
        self.device = device
        self.text_embedder = SentenceTransformer(embed_model_name, device=self.device)

        # âœ… NEW: Chroma 0.5+ compatible client initialization
        self.client = chromadb.PersistentClient(path=persist_directory)

        # Create or get collection
        coll_name = "multimodal_docs"
        existing_collections = [c.name for c in self.client.list_collections()]
        if coll_name in existing_collections:
            self.col = self.client.get_collection(coll_name)
        else:
            self.col = self.client.create_collection(
                name=coll_name,
                metadata={"description": "text+image multimodal"}
            )

    def ingest_pdfs(self, data_dir="data", chunk_chars=900, overlap=200):
        for root, _, files in os.walk(data_dir):
            for fn in files:
                if fn.lower().endswith(".pdf"):
                    path = os.path.join(root, fn)
                    self._process_pdf(path, chunk_chars, overlap)
        print("âœ… PDF ingestion complete. Data persisted to:", os.path.abspath(CHROMA_DIR))

    def _process_pdf(self, path, chunk_chars, overlap):
        doc = fitz.open(path)
        for pno in range(len(doc)):
            page = doc[pno]
            text = page.get_text().strip()

            # ğŸ”¹ Process text chunks
            if text:
                chunks = self._chunk_text(text, chunk_chars, overlap)
                for i, c in enumerate(chunks):
                    emb = self.text_embedder.encode(c)
                    uid = str(uuid.uuid4())
                    meta = {
                        "type": "text",
                        "source": os.path.basename(path),
                        "page": pno + 1,
                        "chunk_idx": i
                    }
                    self.col.add(
                        documents=[c],
                        metadatas=[meta],
                        ids=[uid],
                        embeddings=[emb.tolist()]
                    )

            # ğŸ”¹ Extract and store images
            images = page.get_images(full=True)
            for img_index, img in enumerate(images):
                xref = img[0]
                base_image = doc.extract_image(xref)
                ext = base_image["ext"]
                image_bytes = base_image["image"]

                images_dir = os.path.join(os.path.dirname(path), "images")
                os.makedirs(images_dir, exist_ok=True)
                img_name = f"{os.path.splitext(os.path.basename(path))[0]}_p{pno + 1}_img{img_index}.{ext}"
                img_path = os.path.join(images_dir, img_name)

                with open(img_path, "wb") as f:
                    f.write(image_bytes)

                placeholder_text = f"[IMAGE] {img_name}"
                emb = self.text_embedder.encode(f"image:{img_name}")
                uid = str(uuid.uuid4())
                meta = {
                    "type": "image",
                    "source": os.path.basename(path),
                    "page": pno + 1,
                    "img_path": img_path,
                    "img_name": img_name
                }
                self.col.add(
                    documents=[placeholder_text],
                    metadatas=[meta],
                    ids=[uid],
                    embeddings=[emb.tolist()]
                )

    def _chunk_text(self, text: str, chunk_chars: int, overlap: int) -> List[str]:
        """Split long text into overlapping chunks"""
        chunks = []
        start = 0
        while start < len(text):
            end = min(start + chunk_chars, len(text))
            chunk = text[start:end]
            chunks.append(chunk)
            start += chunk_chars - overlap
        return chunks

    def ingest_images_folder(self, images_dir="data/images"):
        if not os.path.exists(images_dir):
            print("âš ï¸ No image directory found:", images_dir)
            return

        for root, _, files in os.walk(images_dir):
            for fn in files:
                if fn.lower().endswith((".png", ".jpg", ".jpeg")):
                    p = os.path.join(root, fn)
                    placeholder = f"[IMAGE] {fn}"
                    emb = self.text_embedder.encode(f"image:{fn}")
                    uid = str(uuid.uuid4())
                    meta = {
                        "type": "image",
                        "source": fn,
                        "img_path": p,
                        "img_name": fn
                    }
                    self.col.add(
                        documents=[placeholder],
                        metadatas=[meta],
                        ids=[uid],
                        embeddings=[emb.tolist()]
                    )
        print("âœ… Image ingestion complete.")

    # def retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    #     q_emb = self.text_embedder.encode(query)
    #     res = self.col.query(query_embeddings=[q_emb.tolist()], n_results=top_k)
    #     hits = []
    #     docs = res.get("documents", [[]])[0]
    #     metas = res.get("metadatas", [[]])[0]
    #     ids = res.get("ids", [[]])[0]
    #     distances = res.get("distances", [[]])[0]
    #     for idx, doc in enumerate(docs):
    #         hits.append({
    #             "id": ids[idx],
    #             "document": doc,
    #             "metadata": metas[idx],
    #             "distance": distances[idx]
    #         })
    #     return hits

    def retrieve(self, query: str, top_k: int = 5, intent: str = "default") -> List[Dict[str, Any]]:
            q_emb = self.text_embedder.encode(query)

    # ğŸ” If intent is visual â†’ retrieve only image embeddings
            if intent == "visual":
                res = self.col.query(
                    query_embeddings=[q_emb.tolist()],
                    n_results=top_k,
                    where={"type": "image"}   # ğŸ”¥ Only return images
                )
            else:
                # Normal retrieval
                res = self.col.query(
                    query_embeddings=[q_emb.tolist()],
                    n_results=top_k
                )

            hits = []
            docs = res.get("documents", [[]])[0]
            metas = res.get("metadatas", [[]])[0]
            ids = res.get("ids", [[]])[0]
            distances = res.get("distances", [[]])[0]

            for idx, doc in enumerate(docs):
                hits.append({
                    "id": ids[idx],
                    "document": doc,
                    "metadata": metas[idx],
                    "distance": distances[idx]
                })
            return hits


    def get_all_documents(self):
        res = self.col.get()
        rows = []
        for i in range(len(res["ids"])):
            rows.append({
                "id": res["ids"][i],
                "document": res["documents"][i],
                "metadata": res["metadatas"][i]
            })
        return rows

    def update_image_caption_embedding(self, item_id: str, caption: str):
        emb = self.text_embedder.encode(caption)
        self.col.update(
            ids=[item_id],
            embeddings=[emb.tolist()],
            documents=[caption]
        )
